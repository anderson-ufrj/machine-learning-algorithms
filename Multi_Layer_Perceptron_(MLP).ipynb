{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBeT4wzNQj0C"
      },
      "source": [
        "# Multi-Layer Perceptron (MLP) com Iris Dataset\n",
        "\n",
        "## Objetivo\n",
        "Implementação completa de uma rede MLP para classificação multiclasse utilizando o dataset Iris, demonstrando os conceitos fundamentais de redes neurais feedforward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRYNTG56Qj0E"
      },
      "source": [
        "## 1. Importação de Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_hFilaHQj0E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "# Configuração de visualização\n",
        "plt.style.use('seaborn-v0_8')\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rruuwt0ZQj0G"
      },
      "source": [
        "## 2. Carregamento e Análise Exploratória dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E20JGoHbQj0G"
      },
      "outputs": [],
      "source": [
        "# Carregamento do dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "feature_names = iris.feature_names\n",
        "target_names = iris.target_names\n",
        "\n",
        "# Conversão para DataFrame para análise\n",
        "df = pd.DataFrame(X, columns=feature_names)\n",
        "df['target'] = y\n",
        "df['species'] = df['target'].map({i: name for i, name in enumerate(target_names)})\n",
        "\n",
        "print(\"Informações do Dataset:\")\n",
        "print(f\"Shape: {X.shape}\")\n",
        "print(f\"Features: {feature_names}\")\n",
        "print(f\"Classes: {target_names}\")\n",
        "print(\"\\nPrimeiras 5 amostras:\")\n",
        "print(df.head())\n",
        "print(\"\\nEstatísticas descritivas:\")\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GtkkImSQj0G"
      },
      "source": [
        "### Visualização da Distribuição dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-UvLzTGQj0H"
      },
      "outputs": [],
      "source": [
        "# Pairplot para visualizar relações entre features\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.pairplot(df, hue='species', diag_kind='kde', markers=['o', 's', 'D'])\n",
        "plt.suptitle('Distribuição das Features por Espécie', y=1.02)\n",
        "plt.show()\n",
        "\n",
        "# Boxplots para cada feature\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, feature in enumerate(feature_names):\n",
        "    df.boxplot(column=feature, by='species', ax=axes[idx])\n",
        "    axes[idx].set_title(f'Distribuição de {feature}')\n",
        "    axes[idx].set_xlabel('Espécie')\n",
        "    axes[idx].set_ylabel(feature)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_h9KHHPQj0H"
      },
      "source": [
        "## 3. Pré-processamento dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hul4AURzQj0H"
      },
      "outputs": [],
      "source": [
        "# Normalização das features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# One-hot encoding dos labels\n",
        "y_encoded = to_categorical(y, num_classes=3)\n",
        "\n",
        "# Divisão em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Divisão adicional para conjunto de validação\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train.argmax(axis=1)\n",
        ")\n",
        "\n",
        "print(f\"Conjunto de treino: {X_train.shape[0]} amostras\")\n",
        "print(f\"Conjunto de validação: {X_val.shape[0]} amostras\")\n",
        "print(f\"Conjunto de teste: {X_test.shape[0]} amostras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYAQKnIyQj0I"
      },
      "source": [
        "## 4. Arquitetura do MLP\n",
        "\n",
        "### Modelo Base com Configuração Otimizada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GC4EPfqLQj0I"
      },
      "outputs": [],
      "source": [
        "def create_mlp_model(input_dim, hidden_layers, activation='relu', dropout_rate=0.3):\n",
        "    \"\"\"\n",
        "    Cria um modelo MLP configurável.\n",
        "\n",
        "    Args:\n",
        "        input_dim: Dimensão da entrada\n",
        "        hidden_layers: Lista com número de neurônios por camada oculta\n",
        "        activation: Função de ativação para camadas ocultas\n",
        "        dropout_rate: Taxa de dropout\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    # Primeira camada oculta\n",
        "    model.add(Dense(hidden_layers[0], input_dim=input_dim, activation=activation))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Camadas ocultas adicionais\n",
        "    for units in hidden_layers[1:]:\n",
        "        model.add(Dense(units, activation=activation))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Camada de saída\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Criação do modelo\n",
        "model = create_mlp_model(\n",
        "    input_dim=4,\n",
        "    hidden_layers=[64, 32, 16],\n",
        "    activation='relu',\n",
        "    dropout_rate=0.3\n",
        ")\n",
        "\n",
        "# Compilação\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Resumo da arquitetura\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYpHi3rDQj0I"
      },
      "source": [
        "### Visualização da Arquitetura"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcAlOAtiQj0I"
      },
      "outputs": [],
      "source": [
        "# Contagem de parâmetros por camada\n",
        "total_params = 0\n",
        "trainable_params = 0\n",
        "non_trainable_params = 0\n",
        "\n",
        "print(\"\\nDetalhamento dos parâmetros por camada:\\n\")\n",
        "for layer in model.layers:\n",
        "    layer_params = layer.count_params()\n",
        "    if hasattr(layer, 'trainable_weights'):\n",
        "        trainable = sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
        "        non_trainable = layer_params - trainable\n",
        "    else:\n",
        "        trainable = layer_params\n",
        "        non_trainable = 0\n",
        "\n",
        "    print(f\"{layer.name:20} | Parâmetros: {layer_params:7,} | Treináveis: {trainable:7,}\")\n",
        "    total_params += layer_params\n",
        "    trainable_params += trainable\n",
        "    non_trainable_params += non_trainable\n",
        "\n",
        "print(f\"\\nTotal de parâmetros: {total_params:,}\")\n",
        "print(f\"Parâmetros treináveis: {trainable_params:,}\")\n",
        "print(f\"Parâmetros não treináveis: {non_trainable_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6KEs9MMQj0J"
      },
      "source": [
        "## 5. Treinamento do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXBJ7Gn7Qj0J"
      },
      "outputs": [],
      "source": [
        "# Callbacks\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=50,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'best_mlp_model.h5',\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Treinamento\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop, checkpoint],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrC8hwHcQj0J"
      },
      "source": [
        "## 6. Visualização do Histórico de Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTcJhB4nQj0J"
      },
      "outputs": [],
      "source": [
        "# Extração do histórico\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epochs_range = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Plotagem\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Loss\n",
        "axes[0].plot(epochs_range, train_loss, 'b-', label='Loss de Treino', linewidth=2)\n",
        "axes[0].plot(epochs_range, val_loss, 'r-', label='Loss de Validação', linewidth=2)\n",
        "axes[0].set_xlabel('Épocas')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Evolução da Loss durante o Treinamento')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Acurácia\n",
        "axes[1].plot(epochs_range, train_acc, 'b-', label='Acurácia de Treino', linewidth=2)\n",
        "axes[1].plot(epochs_range, val_acc, 'r-', label='Acurácia de Validação', linewidth=2)\n",
        "axes[1].set_xlabel('Épocas')\n",
        "axes[1].set_ylabel('Acurácia')\n",
        "axes[1].set_title('Evolução da Acurácia durante o Treinamento')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Métricas finais\n",
        "final_epoch = len(train_loss)\n",
        "print(f\"\\nMétricas na época {final_epoch}:\")\n",
        "print(f\"Loss de Treino: {train_loss[-1]:.4f}\")\n",
        "print(f\"Loss de Validação: {val_loss[-1]:.4f}\")\n",
        "print(f\"Acurácia de Treino: {train_acc[-1]:.4f}\")\n",
        "print(f\"Acurácia de Validação: {val_acc[-1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II34HsR9Qj0K"
      },
      "source": [
        "## 7. Avaliação no Conjunto de Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_NUVZvjQj0K"
      },
      "outputs": [],
      "source": [
        "# Avaliação\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\nDesempenho no Conjunto de Teste:\")\n",
        "print(f\"Loss: {test_loss:.4f}\")\n",
        "print(f\"Acurácia: {test_acc:.4f}\")\n",
        "\n",
        "# Predições\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = y_pred_proba.argmax(axis=1)\n",
        "y_true = y_test.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwEBCH6wQj0K"
      },
      "source": [
        "## 8. Matriz de Confusão e Relatório de Classificação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y10UN1yMQj0K"
      },
      "outputs": [],
      "source": [
        "# Matriz de confusão\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=target_names, yticklabels=target_names)\n",
        "plt.title('Matriz de Confusão - MLP')\n",
        "plt.ylabel('Classe Verdadeira')\n",
        "plt.xlabel('Classe Predita')\n",
        "plt.show()\n",
        "\n",
        "# Relatório de classificação\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTqtEW3QQj0K"
      },
      "source": [
        "## 9. Análise de Confiança das Predições"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d35ob9UoQj0L"
      },
      "outputs": [],
      "source": [
        "# Análise das probabilidades preditas\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Distribuição das probabilidades máximas\n",
        "max_probs = y_pred_proba.max(axis=1)\n",
        "axes[0].hist(max_probs, bins=20, edgecolor='black', alpha=0.7)\n",
        "axes[0].set_xlabel('Probabilidade Máxima')\n",
        "axes[0].set_ylabel('Frequência')\n",
        "axes[0].set_title('Distribuição da Confiança das Predições')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Heatmap das probabilidades por amostra\n",
        "im = axes[1].imshow(y_pred_proba.T, aspect='auto', cmap='viridis')\n",
        "axes[1].set_yticks(range(3))\n",
        "axes[1].set_yticklabels(target_names)\n",
        "axes[1].set_xlabel('Amostras de Teste')\n",
        "axes[1].set_ylabel('Classes')\n",
        "axes[1].set_title('Probabilidades Preditas por Amostra')\n",
        "plt.colorbar(im, ax=axes[1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Análise de amostras com baixa confiança\n",
        "low_confidence_threshold = 0.7\n",
        "low_confidence_samples = np.where(max_probs < low_confidence_threshold)[0]\n",
        "print(f\"\\nAmostras com confiança < {low_confidence_threshold}: {len(low_confidence_samples)}\")\n",
        "\n",
        "if len(low_confidence_samples) > 0:\n",
        "    print(\"\\nDetalhes das amostras de baixa confiança:\")\n",
        "    for idx in low_confidence_samples[:5]:  # Mostrar apenas as primeiras 5\n",
        "        print(f\"\\nAmostra {idx}:\")\n",
        "        print(f\"  Classe verdadeira: {target_names[y_true[idx]]}\")\n",
        "        print(f\"  Classe predita: {target_names[y_pred[idx]]}\")\n",
        "        print(f\"  Probabilidades: {dict(zip(target_names, y_pred_proba[idx]))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIO2-XR-Qj0L"
      },
      "source": [
        "## 10. Experimentação com Diferentes Funções de Ativação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJecshqWQj0L"
      },
      "outputs": [],
      "source": [
        "# Comparação de funções de ativação\n",
        "activation_functions = ['relu', 'tanh', 'sigmoid', 'elu']\n",
        "results = {}\n",
        "\n",
        "for activation in activation_functions:\n",
        "    print(f\"\\nTreinando modelo com ativação: {activation}\")\n",
        "\n",
        "    # Criar e compilar modelo\n",
        "    model_temp = create_mlp_model(\n",
        "        input_dim=4,\n",
        "        hidden_layers=[64, 32],\n",
        "        activation=activation,\n",
        "        dropout_rate=0.2\n",
        "    )\n",
        "\n",
        "    model_temp.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Treinar (com menos épocas para comparação rápida)\n",
        "    history_temp = model_temp.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Avaliar\n",
        "    test_loss, test_acc = model_temp.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    results[activation] = {\n",
        "        'history': history_temp.history,\n",
        "        'test_acc': test_acc,\n",
        "        'test_loss': test_loss\n",
        "    }\n",
        "\n",
        "    print(f\"  Acurácia no teste: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3OU1_WeQj0L"
      },
      "source": [
        "### Visualização Comparativa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoBnTxZ8Qj0L"
      },
      "outputs": [],
      "source": [
        "# Plotagem comparativa\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "for activation, result in results.items():\n",
        "    epochs = range(1, len(result['history']['loss']) + 1)\n",
        "\n",
        "    # Loss de validação\n",
        "    axes[0].plot(epochs, result['history']['val_loss'], label=activation)\n",
        "\n",
        "    # Acurácia de validação\n",
        "    axes[1].plot(epochs, result['history']['val_accuracy'], label=activation)\n",
        "\n",
        "axes[0].set_xlabel('Épocas')\n",
        "axes[0].set_ylabel('Loss de Validação')\n",
        "axes[0].set_title('Comparação de Loss por Função de Ativação')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].set_xlabel('Épocas')\n",
        "axes[1].set_ylabel('Acurácia de Validação')\n",
        "axes[1].set_title('Comparação de Acurácia por Função de Ativação')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Tabela de resultados finais\n",
        "print(\"\\nResultados finais por função de ativação:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"{'Ativação':>10} | {'Acurácia':>10} | {'Loss':>10}\")\n",
        "print(\"-\" * 40)\n",
        "for activation, result in results.items():\n",
        "    print(f\"{activation:>10} | {result['test_acc']:>10.4f} | {result['test_loss']:>10.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgNpewwzQj0L"
      },
      "source": [
        "## 11. Análise de Sensibilidade dos Pesos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVf7LwEsQj0M"
      },
      "outputs": [],
      "source": [
        "# Análise dos pesos da primeira camada\n",
        "first_layer_weights = model.layers[0].get_weights()[0]  # Pesos\n",
        "first_layer_bias = model.layers[0].get_weights()[1]     # Bias\n",
        "\n",
        "# Visualização dos pesos\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(first_layer_weights.T, aspect='auto', cmap='coolwarm',\n",
        "           vmin=-np.abs(first_layer_weights).max(),\n",
        "           vmax=np.abs(first_layer_weights).max())\n",
        "plt.colorbar(label='Valor do Peso')\n",
        "plt.xlabel('Features de Entrada')\n",
        "plt.ylabel('Neurônios da Primeira Camada Oculta')\n",
        "plt.title('Mapa de Calor dos Pesos da Primeira Camada')\n",
        "plt.xticks(range(4), feature_names, rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Análise da importância das features baseada nos pesos\n",
        "feature_importance = np.abs(first_layer_weights).mean(axis=1)\n",
        "feature_importance_normalized = feature_importance / feature_importance.sum()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "bars = plt.bar(feature_names, feature_importance_normalized)\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Importância Relativa')\n",
        "plt.title('Importância das Features Baseada nos Pesos da Primeira Camada')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Adicionar valores nas barras\n",
        "for bar, importance in zip(bars, feature_importance_normalized):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f'{importance:.3f}', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCyHw0ngQj0M"
      },
      "source": [
        "## 12. Desafio: Problema de Regressão com MLP\n",
        "\n",
        "### Implementação de um MLP para Regressão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNkJOxqDQj0M"
      },
      "outputs": [],
      "source": [
        "# Geração de dados sintéticos para regressão\n",
        "np.random.seed(42)\n",
        "X_reg = np.linspace(-3, 3, 300).reshape(-1, 1)\n",
        "y_reg = X_reg**2 + 0.5 * X_reg**3 + 2 * np.sin(2 * X_reg) + np.random.normal(0, 0.5, X_reg.shape)\n",
        "y_reg = y_reg.ravel()\n",
        "\n",
        "# Divisão dos dados\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_reg, y_reg, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Normalização\n",
        "scaler_X_reg = StandardScaler()\n",
        "X_train_reg_scaled = scaler_X_reg.fit_transform(X_train_reg)\n",
        "X_test_reg_scaled = scaler_X_reg.transform(X_test_reg)\n",
        "\n",
        "# Modelo de regressão\n",
        "model_regression = Sequential([\n",
        "    Dense(64, activation='relu', input_dim=1),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1)  # Sem ativação para regressão\n",
        "])\n",
        "\n",
        "model_regression.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "# Treinamento\n",
        "history_reg = model_regression.fit(\n",
        "    X_train_reg_scaled, y_train_reg,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Avaliação\n",
        "test_loss_reg, test_mae_reg = model_regression.evaluate(\n",
        "    X_test_reg_scaled, y_test_reg, verbose=0\n",
        ")\n",
        "print(f\"\\nResultados da Regressão:\")\n",
        "print(f\"MSE no teste: {test_loss_reg:.4f}\")\n",
        "print(f\"MAE no teste: {test_mae_reg:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khHg8lgbQj0M"
      },
      "source": [
        "### Visualização dos Resultados da Regressão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZluKuCQuQj0M"
      },
      "outputs": [],
      "source": [
        "# Predições\n",
        "X_plot = np.linspace(-3, 3, 500).reshape(-1, 1)\n",
        "X_plot_scaled = scaler_X_reg.transform(X_plot)\n",
        "y_pred_reg = model_regression.predict(X_plot_scaled)\n",
        "\n",
        "# Plotagem\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Dados e predições\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(X_reg, y_reg, alpha=0.5, s=20, label='Dados reais')\n",
        "plt.plot(X_plot, y_pred_reg, 'r-', linewidth=2, label='Predição MLP')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.title('MLP para Regressão Não-Linear')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Histórico de treinamento\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_reg.history['loss'], label='Loss de Treino')\n",
        "plt.plot(history_reg.history['val_loss'], label='Loss de Validação')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('Evolução do Erro durante o Treinamento')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK6bz9PeQj0N"
      },
      "source": [
        "## 13. Conclusões\n",
        "\n",
        "### Principais Observações:\n",
        "\n",
        "1. **Arquitetura MLP**: Demonstramos a implementação completa de um MLP para classificação multiclasse\n",
        "2. **Funções de Ativação**: ReLU mostrou melhor desempenho para este problema\n",
        "3. **Regularização**: Dropout foi eficaz na prevenção de overfitting\n",
        "4. **Versatilidade**: O MLP se adapta tanto para classificação quanto regressão\n",
        "\n",
        "### Conceitos Demonstrados:\n",
        "- Propagação forward através de camadas densas\n",
        "- Importância das funções de ativação não-lineares\n",
        "- Técnicas de regularização (Dropout)\n",
        "- Análise de pesos e importância de features\n",
        "- Adaptação para problemas de regressão\n",
        "\n",
        "### Teorema da Aproximação Universal:\n",
        "Os resultados confirmam a capacidade do MLP de aproximar funções complexas, tanto para classificação quanto para regressão não-linear."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}